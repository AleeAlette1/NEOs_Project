{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75d6f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Resources/complete_merged_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10924/1415263545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#  Import and read the charity_data.csv.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Resources/complete_merged_df.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Resources/complete_merged_df.csv'"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "df = pd.read_csv(\"Resources/complete_merged_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dddacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "\n",
    "df = df.drop(columns =[\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be23e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ab78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to select top 4 important variables based on the results of RandomForest sampling\n",
    "nn_df = df[[\"moid\",\"moid_ld\",\"h\",\"h_cad\",\"pha\",\"v_rel\",\"v_inf\"]]\n",
    "nn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1282ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "nn_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the value counts for binning\n",
    "moid_counts = nn_df.moid.value_counts()\n",
    "print(moid_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cae41d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10924/2702466241.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split our preprocessed data into our features and target arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pha\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y=nn_df.pha\n",
    "X=nn_df.drop(\"pha\",axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935be699",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10924/3690512841.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Fit the StandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Scale the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "604b1641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# defining the number of training features\n",
    "print(len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d23aca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12)                84        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 12)                156       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 253\n",
      "Trainable params: 253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 12\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59be07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43a72633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "542dd712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0160c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.9281\n",
      "Epoch 2/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9826\n",
      "Epoch 3/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9883\n",
      "Epoch 4/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9910\n",
      "Epoch 5/100\n",
      "507/528 [===========================>..] - ETA: 0s - loss: 0.0250 - accuracy: 0.9922\n",
      "Epoch 00005: saving model to checkpoints\\weights.05hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9923\n",
      "Epoch 6/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9934\n",
      "Epoch 7/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9941\n",
      "Epoch 8/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9942\n",
      "Epoch 9/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0161 - accuracy: 0.9950\n",
      "Epoch 10/100\n",
      "513/528 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 00010: saving model to checkpoints\\weights.10hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0152 - accuracy: 0.9952\n",
      "Epoch 11/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 12/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0140 - accuracy: 0.9950\n",
      "Epoch 13/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0136 - accuracy: 0.9952\n",
      "Epoch 14/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 15/100\n",
      "512/528 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9951\n",
      "Epoch 00015: saving model to checkpoints\\weights.15hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0133 - accuracy: 0.9951\n",
      "Epoch 16/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9952\n",
      "Epoch 17/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 18/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0125 - accuracy: 0.9957\n",
      "Epoch 19/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 20/100\n",
      "507/528 [===========================>..] - ETA: 0s - loss: 0.0119 - accuracy: 0.9955\n",
      "Epoch 00020: saving model to checkpoints\\weights.20hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0118 - accuracy: 0.9954\n",
      "Epoch 21/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9955\n",
      "Epoch 22/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0119 - accuracy: 0.9957\n",
      "Epoch 23/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 24/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0117 - accuracy: 0.9957\n",
      "Epoch 25/100\n",
      "525/528 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9964\n",
      "Epoch 00025: saving model to checkpoints\\weights.25hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0110 - accuracy: 0.9964\n",
      "Epoch 26/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9963\n",
      "Epoch 27/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 28/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 29/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0110 - accuracy: 0.9958\n",
      "Epoch 30/100\n",
      "525/528 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 00030: saving model to checkpoints\\weights.30hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 31/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 32/100\n",
      "528/528 [==============================] - 1s 3ms/step - loss: 0.0108 - accuracy: 0.9957\n",
      "Epoch 33/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 34/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0107 - accuracy: 0.9964\n",
      "Epoch 35/100\n",
      "504/528 [===========================>..] - ETA: 0s - loss: 0.0107 - accuracy: 0.9958\n",
      "Epoch 00035: saving model to checkpoints\\weights.35hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0106 - accuracy: 0.9959\n",
      "Epoch 36/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 37/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9963\n",
      "Epoch 38/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9959\n",
      "Epoch 39/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9962\n",
      "Epoch 40/100\n",
      "511/528 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 00040: saving model to checkpoints\\weights.40hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 41/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 42/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 43/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 44/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9967\n",
      "Epoch 45/100\n",
      "510/528 [===========================>..] - ETA: 0s - loss: 0.0103 - accuracy: 0.9960\n",
      "Epoch 00045: saving model to checkpoints\\weights.45hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9960\n",
      "Epoch 46/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 47/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9961\n",
      "Epoch 48/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9966\n",
      "Epoch 49/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0098 - accuracy: 0.9965\n",
      "Epoch 50/100\n",
      "505/528 [===========================>..] - ETA: 0s - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 00050: saving model to checkpoints\\weights.50hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 51/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9965\n",
      "Epoch 52/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9963\n",
      "Epoch 53/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9966\n",
      "Epoch 54/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9964\n",
      "Epoch 55/100\n",
      "520/528 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9965\n",
      "Epoch 00055: saving model to checkpoints\\weights.55hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9966\n",
      "Epoch 56/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9966\n",
      "Epoch 57/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9967\n",
      "Epoch 58/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9959\n",
      "Epoch 59/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9961\n",
      "Epoch 60/100\n",
      "518/528 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9967\n",
      "Epoch 00060: saving model to checkpoints\\weights.60hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9966\n",
      "Epoch 61/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9965\n",
      "Epoch 62/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9962: 0s - l\n",
      "Epoch 63/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9964\n",
      "Epoch 64/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9961\n",
      "Epoch 65/100\n",
      "505/528 [===========================>..] - ETA: 0s - loss: 0.0090 - accuracy: 0.9967\n",
      "Epoch 00065: saving model to checkpoints\\weights.65hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 66/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9965\n",
      "Epoch 67/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9965\n",
      "Epoch 68/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9968\n",
      "Epoch 69/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 70/100\n",
      "527/528 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9966\n",
      "Epoch 00070: saving model to checkpoints\\weights.70hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9966\n",
      "Epoch 71/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9962\n",
      "Epoch 72/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9964\n",
      "Epoch 73/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9965\n",
      "Epoch 74/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 75/100\n",
      "525/528 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9968\n",
      "Epoch 00075: saving model to checkpoints\\weights.75hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 76/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9968\n",
      "Epoch 77/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 78/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9965\n",
      "Epoch 79/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0087 - accuracy: 0.9969\n",
      "Epoch 80/100\n",
      "524/528 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9963\n",
      "Epoch 00080: saving model to checkpoints\\weights.80hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9963\n",
      "Epoch 81/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9964\n",
      "Epoch 82/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0088 - accuracy: 0.9966\n",
      "Epoch 83/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9965\n",
      "Epoch 84/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9965\n",
      "Epoch 85/100\n",
      "525/528 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9962\n",
      "Epoch 00085: saving model to checkpoints\\weights.85hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9962\n",
      "Epoch 86/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 87/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 88/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9968: 0s\n",
      "Epoch 89/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9967\n",
      "Epoch 90/100\n",
      "522/528 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 00090: saving model to checkpoints\\weights.90hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 91/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0087 - accuracy: 0.9967\n",
      "Epoch 92/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9961\n",
      "Epoch 93/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 94/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9964\n",
      "Epoch 95/100\n",
      "513/528 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 00095: saving model to checkpoints\\weights.95hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 96/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0088 - accuracy: 0.9968 E\n",
      "Epoch 97/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9972\n",
      "Epoch 98/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0088 - accuracy: 0.9964\n",
      "Epoch 99/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0084 - accuracy: 0.9968\n",
      "Epoch 100/100\n",
      "517/528 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 00100: saving model to checkpoints\\weights.100hdf5\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9974\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7336f88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 - 0s - loss: 0.0060 - accuracy: 0.9977 - 371ms/epoch - 2ms/step\n",
      "Loss: 0.005975833162665367, Accuracy: 0.9976884722709656\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2dc83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to HDF5 file\n",
    "nn.save(\"Resources/NEOs_project_NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b79ebb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5624\n"
     ]
    }
   ],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = nn.predict(X_test_scaled)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9eff1b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00]\n",
      " [1.7818139e-17]\n",
      " [0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PHA Predict'] = lambda x: 0 if x < 0.5 else 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
